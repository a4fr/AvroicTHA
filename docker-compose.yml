---
services:

  # https://github.com/confluentinc/cp-all-in-one/blob/7.8.0-post/cp-all-in-one-community/docker-compose.yml
  broker:
    image: confluentinc/cp-kafka:7.8.0
    hostname: broker
    container_name: broker
    ports:
      - "9092:9092"
      - "9101:9101"
    environment:
      KAFKA_NODE_ID: 1
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: 'CONTROLLER:PLAINTEXT,PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT'
      KAFKA_ADVERTISED_LISTENERS: 'PLAINTEXT://broker:29092,PLAINTEXT_HOST://localhost:9092'
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 0
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_JMX_PORT: 9101
      KAFKA_JMX_HOSTNAME: localhost
      KAFKA_PROCESS_ROLES: 'broker,controller'
      KAFKA_CONTROLLER_QUORUM_VOTERS: '1@broker:29093'
      KAFKA_LISTENERS: 'PLAINTEXT://broker:29092,CONTROLLER://broker:29093,PLAINTEXT_HOST://0.0.0.0:9092'
      KAFKA_INTER_BROKER_LISTENER_NAME: 'PLAINTEXT'
      KAFKA_CONTROLLER_LISTENER_NAMES: 'CONTROLLER'
      KAFKA_LOG_DIRS: '/tmp/kraft-combined-logs'
      CLUSTER_ID: 'pBAy1e8ISdWxpL0i49mZYQ'
    networks:
      - avroic

  # https://github.com/kafbat/kafka-ui/blob/main/documentation/compose/kafbat-ui.yaml
  kafbat-ui:
    container_name: kafbat-ui
    image: ghcr.io/kafbat/kafka-ui:latest
    restart: always
    ports:
      - 8080:8080
    depends_on:
      - broker
    environment:
      KAFKA_CLUSTERS_0_NAME: local
      KAFKA_CLUSTERS_0_BOOTSTRAPSERVERS: broker:29092
      KAFKA_CLUSTERS_0_METRICS_PORT: 9997
      KAFKA_CLUSTERS_0_SCHEMAREGISTRY: http://schema-registry:8081
      DYNAMIC_CONFIG_ENABLED: 'true'
    networks:
      - avroic

  data-producer:
    build:
      context: ./01-DataProducer
      dockerfile: Dockerfile
    container_name: data-producer
    depends_on:
      - broker
    environment:
      KAFKA_BROKER: broker:29092
      KAFKA_TOPIC: avroic
      KAFKA_TOPIC_PARTITION: 4
      KAFKA_TOPIC_REPLICATION_FACTOR: 1
      RANDOM_DATA_MAX_USERS: 10
      RANDOM_DATA_MAX_ITEMS: 10
      PRODUCER_RATE: 1
    networks:
      - avroic

  spark-master:
    container_name: spark-master
    build:
      context: ./02-StreamProcessing
      dockerfile: Dockerfile
    depends_on:
      - broker
    environment:
      SPARK_MODE: master
      SPARK_RPC_AUTHENTICATION_ENABLED: no
      SPARK_RPC_ENCRYPTION_ENABLED: no
      SPARK_LOCAL_STORAGE_ENCRYPTION_ENABLED: no
      SPARK_SSL_ENABLED: no
      KAFKA_BROKER: broker:29092
      KAFKA_TOPIC: avroic
      DEPLOY_MODE: cluster
      SPARK_MASTER_URL: spark://spark-master:7077
      LOOP_SLEEP: 2
    ports:
      - "7077:7077"
      - "8180:8080"
    networks:
      - avroic

  spark-worker:
    image: bitnami/spark:3.5.0
    environment:
      - SPARK_MODE=client
      - SPARK_MASTER_URL=spark://spark-master:7077
      - SPARK_WORKER_MEMORY=2G
      - SPARK_WORKER_CORES=2
    depends_on:
      - spark-master
    networks:
      - avroic
    deploy:
      replicas: 2

  elasticsearch:
    container_name: elasticsearch
    image: elasticsearch:7.17.26
    environment:
      discovery.type: 'single-node'
    ports:
      - 9200:9200
      - 9300:9300
    networks:
      - avroic

  kibana:
    image: kibana:7.17.26
    volumes:
      - ./kibana.yml:/usr/share/kibana/config/kibana.yml
    ports:
      - 5601:5601
    networks:
      - avroic

  elasticsearch-sink-alert:
    build:
      context: ./03-ElasticsearchSink-Alert
      dockerfile: Dockerfile
    container_name: elasticsearch-sink-alert
    depends_on:
      - broker
      - elasticsearch
    environment:
      KAFKA_BROKER: broker:29092
      KAFKA_TOPIC: avroic_aggregated
      KAFKA_GROUP_ID: ElasticsearchSink-Alert
      ES_HOST: http://elasticsearch:9200
    networks:
      - avroic

networks:
  avroic:
    driver: bridge
